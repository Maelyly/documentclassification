{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./')\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.layers import Convolution1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import ThresholdedReLU\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import h5py\n",
    "from keras.models import Model\n",
    "from keras import Input\n",
    "from keras import optimizers\n",
    "import os, shutil\n",
    "from os import listdir\n",
    "from os.path import isfile, join, isdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get dataset classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {}\n",
    "images_path = 'data/tobacco3482jpg/'\n",
    "classes_dirs = [f for f in listdir(images_path) if isdir(join(images_path, f))]\n",
    "print('Classes Found:')\n",
    "for image_class in classes_dirs:\n",
    "    classes[image_class] = {}\n",
    "    print(image_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create train and validation dir for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'data/tobacco3482jpg/'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "os.mkdir(train_dir)\n",
    "\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "os.mkdir(validation_dir)\n",
    "\n",
    "for image_class in classes_dirs:\n",
    "    \n",
    "    classes[image_class]['train_dir'] = os.path.join(train_dir, image_class)\n",
    "    os.mkdir(classes[image_class]['train_dir'])\n",
    "\n",
    "    classes[image_class]['validation_dir'] = os.path.join(validation_dir, image_class)\n",
    "    os.mkdir(classes[image_class]['validation_dir'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all images file name for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_class in classes_dirs:\n",
    "    images_path = 'data/tobacco3482jpg/{}/'.format(image_class)\n",
    "    classes[image_class]['images'] = [f for f in listdir(images_path) if isfile(join(images_path, f))]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set validation and train size\n",
    "### Downsample_factor is used to get only a % of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.7\n",
    "validation_size = 1 - train_size\n",
    "downsample_factor = 1\n",
    "\n",
    "for image_classe, class_data in classes.items():\n",
    "    class_data['len_train'] = int(len(class_data['images']) * train_size * downsample_factor)\n",
    "    class_data['len_validation'] = int(len(class_data['images']) * validation_size * downsample_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move files inside class folders to their respective folder inside train and validation folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_class, class_data in classes.items():\n",
    "    original_dir = base_dir + image_class + '/'\n",
    "    images = class_data['images']\n",
    "    len_train = class_data['len_train']\n",
    "    len_validation = class_data['len_validation']\n",
    "    for file in images[:len_train]:        \n",
    "        src = os.path.join(original_dir, file)\n",
    "        dst = os.path.join(class_data['train_dir'], file)\n",
    "        shutil.copyfile(src, dst)\n",
    "    \n",
    "    for file in images[len_train:len_train + len_validation]:\n",
    "        src = os.path.join(original_dir, file)\n",
    "        dst = os.path.join(class_data['validation_dir'], file)\n",
    "        shutil.copyfile(src, dst)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_class, class_data in classes.items():\n",
    "    print('\\ntotal training {} images:'.format(image_class), len(os.listdir(class_data['train_dir'])))\n",
    "    print('total validation {} images:'.format(image_class), len(os.listdir(class_data['validation_dir'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_height = 150\n",
    "image_width = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input = Input(shape=(image_height, image_width, 1), name='sent_input', dtype='float32')\n",
    "x = layers.Conv2D(20, (7, 7), activation='relu',input_shape=(image_height, image_width, 1))(image_input)\n",
    "x = layers.MaxPooling2D((4, 4))(x)\n",
    "x = layers.Conv2D(50, (5, 5), activation='relu')(x)\n",
    "x = layers.MaxPooling2D((4, 4))(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dropout(0.5, noise_shape=None, seed=None)(x)\n",
    "output = layers.Dense(8, activation='softmax')(x)\n",
    "\n",
    "model_func = Model(image_input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll1(y_true, y_pred):\n",
    "    \"\"\" Negative log likelihood. \"\"\"\n",
    "    return K.sum(K.binary_crossentropy(y_true, y_pred), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr=0.01)\n",
    "\n",
    "model_func.compile(loss=nll1,\n",
    "optimizer=sgd,\n",
    "metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create generator to train on batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(image_height, image_width),\n",
    "    batch_size=20,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(image_height, image_width),\n",
    "    batch_size=20,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale')\n",
    "\n",
    "print(len(train_generator))\n",
    "print(len(validation_generator))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model_func.fit_generator(\n",
    "train_generator,\n",
    "steps_per_epoch=train_generator.samples,\n",
    "epochs=8,\n",
    "validation_data=validation_generator,\n",
    "validation_steps=validation_generator.samples,\n",
    "verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_func.save('document_classification.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
