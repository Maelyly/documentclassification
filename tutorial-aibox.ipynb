{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/caio/aibox/env-flask-nlp/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/caio/aibox/env-flask-nlp/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/caio/aibox/env-flask-nlp/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/caio/aibox/env-flask-nlp/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/caio/aibox/env-flask-nlp/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/caio/aibox/env-flask-nlp/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./')\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.layers import Convolution1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import ThresholdedReLU\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import h5py\n",
    "from keras.models import Model\n",
    "from keras import Input\n",
    "from keras import optimizers\n",
    "import os, shutil\n",
    "from os import listdir\n",
    "from os.path import isfile, join, isdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes Found:\n",
      "Note\n",
      "News\n",
      "Scientific\n",
      "Memo\n",
      "Email\n",
      "Form\n",
      "ADVE\n",
      "Resume\n",
      "Letter\n",
      "Report\n"
     ]
    }
   ],
   "source": [
    "classes = {}\n",
    "images_path = 'data/tobacco3482jpg/'\n",
    "classes_dirs = [f for f in listdir(images_path) if isdir(join(images_path, f))]\n",
    "print('Classes Found:')\n",
    "for image_class in classes_dirs:\n",
    "    classes[image_class] = {}\n",
    "    print(image_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'data/tobacco3482jpg/'\n",
    "\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "os.mkdir(train_dir)\n",
    "\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "os.mkdir(validation_dir)\n",
    "\n",
    "for image_class in classes_dirs:\n",
    "    \n",
    "    classes[image_class]['train_dir'] = os.path.join(train_dir, image_class)\n",
    "    os.mkdir(classes[image_class]['train_dir'])\n",
    "\n",
    "    classes[image_class]['validation_dir'] = os.path.join(validation_dir, image_class)\n",
    "    os.mkdir(classes[image_class]['validation_dir'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_class in classes_dirs:\n",
    "    images_path = 'data/tobacco3482jpg/{}/'.format(image_class)\n",
    "    classes[image_class]['images'] = [f for f in listdir(images_path) if isfile(join(images_path, f))]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.7\n",
    "validation_size = 1 - train_size\n",
    "downsample_factor = 0.2\n",
    "\n",
    "for image_classe, class_data in classes.items():\n",
    "    class_data['len_train'] = int(len(class_data['images']) * train_size * downsample_factor)\n",
    "    class_data['len_validation'] = int(len(class_data['images']) * validation_size * downsample_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_class, class_data in classes.items():\n",
    "    original_dir = base_dir + image_class + '/'\n",
    "    images = class_data['images']\n",
    "    len_train = class_data['len_train']\n",
    "    len_validation = class_data['len_validation']\n",
    "    for file in images[:len_train]:        \n",
    "        src = os.path.join(original_dir, file)\n",
    "        dst = os.path.join(class_data['train_dir'], file)\n",
    "        shutil.copyfile(src, dst)\n",
    "    \n",
    "    for file in images[len_train:len_train + len_validation]:\n",
    "        src = os.path.join(original_dir, file)\n",
    "        dst = os.path.join(class_data['validation_dir'], file)\n",
    "        shutil.copyfile(src, dst)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "total training Note images: 28\n",
      "total validation Note images: 12\n",
      "\n",
      "total training News images: 26\n",
      "total validation News images: 11\n",
      "\n",
      "total training Scientific images: 36\n",
      "total validation Scientific images: 15\n",
      "\n",
      "total training Memo images: 86\n",
      "total validation Memo images: 37\n",
      "\n",
      "total training Email images: 84\n",
      "total validation Email images: 36\n",
      "\n",
      "total training Form images: 60\n",
      "total validation Form images: 25\n",
      "\n",
      "total training ADVE images: 32\n",
      "total validation ADVE images: 13\n",
      "\n",
      "total training Resume images: 16\n",
      "total validation Resume images: 7\n",
      "\n",
      "total training Letter images: 79\n",
      "total validation Letter images: 34\n",
      "\n",
      "total training Report images: 37\n",
      "total validation Report images: 15\n"
     ]
    }
   ],
   "source": [
    "for image_class, class_data in classes.items():\n",
    "    print('\\ntotal training {} images:'.format(image_class), len(os.listdir(class_data['train_dir'])))\n",
    "    print('total validation {} images:'.format(image_class), len(os.listdir(class_data['validation_dir'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_height = 150\n",
    "image_width = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll1(y_true, y_pred):\n",
    "    \"\"\" Negative log likelihood. \"\"\"\n",
    "\n",
    "    # keras.losses.binary_crossentropy give the mean\n",
    "    # over the last axis. we require the sum\n",
    "    return K.sum(K.binary_crossentropy(y_true, y_pred), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/caio/aibox/env-flask-nlp/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "image_input = Input(shape=(image_height, image_width, 1), name='sent_input', dtype='float32')\n",
    "x = layers.Conv2D(20, (7, 7), activation='relu',input_shape=(image_height, image_width, 1))(image_input)\n",
    "x = layers.MaxPooling2D((4, 4))(x)\n",
    "x = layers.Conv2D(50, (5, 5), activation='relu')(x)\n",
    "x = layers.MaxPooling2D((4, 4))(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "output = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model_func = Model(image_input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr=0.01)\n",
    "\n",
    "model_func.compile(loss=nll1,\n",
    "optimizer=sgd,\n",
    "metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 391 images belonging to 10 classes.\n",
      "Found 38 images belonging to 10 classes.\n",
      "20\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(image_height, image_width),\n",
    "    batch_size=20,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    color_mode='grayscale')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(image_height, image_width),\n",
    "    batch_size=20,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    color_mode='grayscale')\n",
    "\n",
    "print(len(train_generator))\n",
    "print(len(validation_generator))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "133/391 [=========>....................] - ETA: 1:27 - loss: 3.0778 - acc: 0.2152"
     ]
    }
   ],
   "source": [
    "history = model_func.fit_generator(\n",
    "train_generator,\n",
    "steps_per_epoch=train_generator.samples,\n",
    "epochs=8,\n",
    "validation_data=validation_generator,\n",
    "validation_steps=validation_generator.samples,\n",
    "verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_func.save('document_classification.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
